{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 13:12:05.060390: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu\n",
      "2022-04-15 13:12:05.060410: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/train.csv\", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = np.array(dataset.iloc[:, 2])\n",
    "train_ds = np.array([[x] for x in train_ds])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = np.array(dataset.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2'\n",
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(1, activation=tf.sigmoid, name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "# steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "# num_train_steps = steps_per_epoch * epochs\n",
    "# num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "# init_lr = 3e-5\n",
    "# optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "#                                           num_train_steps=num_train_steps,\n",
    "#                                           num_warmup_steps=num_warmup_steps,\n",
    "#                                           optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer='adam',\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/gilberto/spring22/data/Final_Project/bert.ipynb Cell 11'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gilberto/spring22/data/Final_Project/bert.ipynb#ch0000009?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m classifier_model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtrain_ds,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gilberto/spring22/data/Final_Project/bert.ipynb#ch0000009?line=1'>2</a>\u001b[0m                                validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gilberto/spring22/data/Final_Project/bert.ipynb#ch0000009?line=2'>3</a>\u001b[0m                                epochs\u001b[39m=\u001b[39;49mepochs)\n",
      "File \u001b[0;32m~/spring22/data/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/spring22/data/venv/lib/python3.8/site-packages/keras/engine/training.py:1323\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/engine/training.py?line=1315'>1316</a>\u001b[0m \u001b[39mif\u001b[39;00m validation_split:\n\u001b[1;32m   <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/engine/training.py?line=1316'>1317</a>\u001b[0m   \u001b[39m# Create the validation data using the training data. Only supported for\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/engine/training.py?line=1317'>1318</a>\u001b[0m   \u001b[39m# `Tensor` and `NumPy` input.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/engine/training.py?line=1318'>1319</a>\u001b[0m   (x, y, sample_weight), validation_data \u001b[39m=\u001b[39m (\n\u001b[1;32m   <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/engine/training.py?line=1319'>1320</a>\u001b[0m       data_adapter\u001b[39m.\u001b[39mtrain_validation_split(\n\u001b[1;32m   <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/engine/training.py?line=1320'>1321</a>\u001b[0m           (x, y, sample_weight), validation_split\u001b[39m=\u001b[39mvalidation_split))\n\u001b[0;32m-> <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/engine/training.py?line=1322'>1323</a>\u001b[0m \u001b[39mif\u001b[39;00m validation_data:\n\u001b[1;32m   <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/engine/training.py?line=1323'>1324</a>\u001b[0m   val_x, val_y, val_sample_weight \u001b[39m=\u001b[39m (\n\u001b[1;32m   <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/engine/training.py?line=1324'>1325</a>\u001b[0m       data_adapter\u001b[39m.\u001b[39munpack_x_y_sample_weight(validation_data))\n\u001b[1;32m   <a href='file:///home/gilberto/spring22/data/venv/lib/python3.8/site-packages/keras/engine/training.py?line=1326'>1327</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39m_should_use_with_coordinator:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 5, ..., 2, 3, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gave this to my dad for a gag gift after directing \"Nunsense,\" he got a reall kick out of it!',\n",
       "       'I hope a lot of people hear this cd. We need more strong and positive vibes like this. Great vocals, fresh tunes, cross-cultural happiness. Her blues is from the gut. The pop sounds are catchy and mature.',\n",
       "       \"I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\",\n",
       "       ...,\n",
       "       \"We have a small house, and really wanted two of these high chairs for our twins. Space-wize, they are great; they have a small footprint and look nice along side the rest of our furniture.The 2nd tray and the slide-out cup holders are a great addition to this high chair. The shelf under the seat is a great place to store bibs.The downside of the Eddie Bauer high chair is that its difficult to clean. I have toddler twins, I don't have a lot of time to spend cleaning their high chairs with a toothbrush! The slats on the side of the seat are close together and food gets slopped in between them at every meal. If you don't throughly clean this up after each meal, it dries and is difficult to get clean.Another downside is my kids never really fit well into these highchairs. They were always too short for the tray, and the tray was always too far away as opposed to other highchairs. This helped create even more food mess!\",\n",
       "       \"I agree with everyone else who says this chair is hard to clean. I bought the lighter colored wood chair, which really makes the grime build up noticeable, especially on the foot rest. We clean the high chair all the time, but the wood almost has an absorbency about it and there's just so much you're able to get clean. And I'm not sure why some areas that have been cleaned have a sticky feeling to them except that maybe it's a reaction of the wood to the chemicals in disinfectant wipes. It looks nice, but I wish I had gone with a plastic, easier to clean high chair.\",\n",
       "       \"not sure what this book is supposed to be. It is really just a rehash of very old ideas about Carroll with some pop culture uncomfortably tacked on. The 'myth' has been dealt with far better by people who really seem to understand it (it's too deep I think for Brooker's milieu), and the pop culture is presented without any kind of analysis or penetration.I think you are better off with Leach's 'In the Shadow of the Dreamchild' or Sigler's 'Alternative Alices'.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61ca4e05c54118fa8f61d0b49cbdb5dd5e6b9d5cabc85e510088cea3aaf415c5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
